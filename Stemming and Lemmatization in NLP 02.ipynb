{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd320878",
   "metadata": {},
   "source": [
    "# <center>NLPðŸ’¬ðŸ”‰ By ðŸŽ¯Udaya ( Data Engineer ðŸ“š) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848c8dce",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP).\n",
    "* \"running\" -> \"run\"\n",
    "* \"happiness\" -> \"happi\"\n",
    "* \"caresses\" -> \"caress\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d00e84",
   "metadata": {},
   "source": [
    "### Overstemming\n",
    "Definition: Overstemming occurs when a stemming algorithm removes more characters than necessary, leading to stems that are too general or incorrect.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "* \"university\" -> \"univers\" (correct stem: \"universi\")\n",
    "* \"generalization\" -> \"gener\" (correct stem: \"general\")\n",
    "### Understemming\n",
    "Definition: Understemming occurs when a stemming algorithm does not remove enough characters, leading to stems that are too specific and fail to capture the common root of related words.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "* \"running\" -> \"running\" (correct stem: \"run\")\n",
    "* \"happiness\" -> \"happiness\" (correct stem: \"happi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4391ef",
   "metadata": {},
   "source": [
    "### Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac89437",
   "metadata": {},
   "source": [
    "## Porter Stemmer\n",
    "Definition: The Porter Stemmer is one of the most widely used stemming algorithms. It uses a series of predefined rules to iteratively strip suffixes from words.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "* \"running\" -> \"run\"\n",
    "* \"happiness\" -> \"happi\"\n",
    "* \"caresses\" -> \"caress\"\n",
    "* Code ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2cd22fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ðŸ‘‰--> eat\n",
      "eats ðŸ‘‰--> eat\n",
      "eaten ðŸ‘‰--> eaten\n",
      "writing ðŸ‘‰--> write\n",
      "writes ðŸ‘‰--> write\n",
      "programming ðŸ‘‰--> program\n",
      "programs ðŸ‘‰--> program\n",
      "history ðŸ‘‰--> histori\n",
      "finally ðŸ‘‰--> final\n",
      "finalized ðŸ‘‰--> final\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemming = PorterStemmer()\n",
    "\n",
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]\n",
    "\n",
    "for word in words:\n",
    "    print(word+\" ðŸ‘‰--> \"+stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cca8809c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('Congratulation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eee484e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sit'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"sitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dd5151",
   "metadata": {},
   "source": [
    "## Lancaster Stemmer\n",
    "Definition: The Lancaster Stemmer is another stemming algorithm that is more aggressive than the Porter Stemmer. It uses a more extensive set of rules, resulting in shorter stems.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "* \"running\" -> \"run\"\n",
    "* \"happiness\" -> \"happy\"\n",
    "* \"caresses\" -> \"caress\"\n",
    "* Code ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad442381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ðŸ‘‰--> run\n",
      "happiness ðŸ‘‰--> happy\n",
      "caresses ðŸ‘‰--> caress\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "words = [\"running\", \"happiness\", \"caresses\"]\n",
    "for word in words:\n",
    "    print(word+\" ðŸ‘‰--> \"+lancaster.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53bcecae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congrat'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lancaster.stem('Congratulation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b03105",
   "metadata": {},
   "source": [
    "## RegexpStemmer class\n",
    "NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression. Let us see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6b48762",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n",
      "ingeat\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "reg_stemmer=RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
    "\n",
    "print(reg_stemmer.stem('eating'))\n",
    "print(reg_stemmer.stem('ingeating'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d8eae9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['runn', 'happi', 'caresse']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def regex_stem(word):\n",
    "    patterns = [\n",
    "        (r'ing$', ''),  # remove 'ing'\n",
    "        (r'ness$', ''), # remove 'ness'\n",
    "        (r'es$', 'e'),  # replace 'es' with 'e'\n",
    "        (r's$', '')     # remove 's'\n",
    "    ]\n",
    "    for pattern, repl in patterns:\n",
    "        word = re.sub(pattern, repl, word)\n",
    "    return word\n",
    "\n",
    "words = [\"running\", \"happiness\", \"caresses\"]\n",
    "stems = [regex_stem(word) for word in words]\n",
    "print(stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3f4e97",
   "metadata": {},
   "source": [
    "## Snowball Stemmer\n",
    "It is a stemming algorithm which is also known as the Porter2 stemming algorithm as it is a better version of the Porter Stemmer since some issues of it were fixed in this stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68c63cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eatingðŸ‘‰->eat\n",
      "eatsðŸ‘‰->eat\n",
      "eatenðŸ‘‰->eaten\n",
      "writingðŸ‘‰->write\n",
      "writesðŸ‘‰->write\n",
      "programmingðŸ‘‰->program\n",
      "programsðŸ‘‰->program\n",
      "historyðŸ‘‰->histori\n",
      "finallyðŸ‘‰->final\n",
      "finalizedðŸ‘‰->final\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowballsstemmer=SnowballStemmer('english')\n",
    "\n",
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]\n",
    "for word in words:\n",
    "    print(word+\"ðŸ‘‰->\"+snowballsstemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c25f18a",
   "metadata": {},
   "source": [
    "### `Porter Stemmer` v/s `Snowball Stemmer`\n",
    "#### `Example ðŸ‘‡`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60a9e83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter: ['fairli', 'sportingli', 'goe']\n",
      "Snowball: ['fair', 'sport', 'goe']\n"
     ]
    }
   ],
   "source": [
    "porter_stems = [stemming.stem(word) for word in [\"fairly\", \"sportingly\", \"goes\"]]\n",
    "snowball_stems = [snowballsstemmer.stem(word) for word in [\"fairly\", \"sportingly\", \"goes\"]]\n",
    "\n",
    "print(\"Porter:\", porter_stems)  \n",
    "print(\"Snowball:\", snowball_stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf880631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli', 'goe')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"fairly\"),stemming.stem(\"sportingly\"),stemming.stem('goes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9aba890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport', 'goe')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballsstemmer.stem(\"fairly\"),snowballsstemmer.stem(\"sportingly\"),snowballsstemmer.stem('goes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7678ce80",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "* Lemmatization technique is like stemming.\n",
    "*  The output we will get after lemmatization is called â€˜lemmaâ€™, which is a root word rather than root stem, the output of stemming.\n",
    "*  After lemmatization, we will be getting a valid word that means the same thing.\n",
    "* Lemmatization is a process in natural language processing (NLP) that reduces words to their base or dictionary form, known as the lemma.\n",
    "*  Unlike stemming, which often removes suffixes in a crude way, lemmatization uses linguistic knowledge, including vocabulary and morphological analysis, to produce more accurate and meaningful base forms.\n",
    "\n",
    "### Example\n",
    "#### Consider the following words and how they are lemmatized:\n",
    "\n",
    "#### Running:\n",
    "* Lemmatized: \"run\" (verb)\n",
    "* Explanation: The verb \"running\" is reduced to its base form \"run\".\n",
    "#### Better:\n",
    "* Lemmatized: \"good\" (adjective)\n",
    "* Explanation: The adjective \"better\" is reduced to \"good\" based on its comparative form.\n",
    "#### Geese:\n",
    "* Lemmatized: \"goose\" (noun)\n",
    "* Explanation: The plural noun \"geese\" is reduced to its singular form \"goose\".\n",
    "\n",
    "### Wordnet Lemmatizer\n",
    "NLTK provides WordNetLemmatizer class which is a thin wrapper around the wordnet corpus. This class uses morphy() function to the WordNet CorpusReader class to find a lemma. Let us understand it with an example âˆ’\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0eeb150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'going'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "lemmatizer.lemmatize(\"going\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba468caa",
   "metadata": {},
   "source": [
    "#### POS tag - \n",
    "* Noun-n\n",
    "* verb-v\n",
    "* adjective-a\n",
    "* adverb-r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "810bbdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"going\",pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "017d960b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'going'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"going\",pos='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07e30f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eatingðŸ‘‰-> eat\n",
      "eatsðŸ‘‰-> eat\n",
      "eatenðŸ‘‰-> eat\n",
      "writingðŸ‘‰-> write\n",
      "writesðŸ‘‰-> write\n",
      "programmingðŸ‘‰-> program\n",
      "programsðŸ‘‰-> program\n",
      "historyðŸ‘‰-> history\n",
      "finallyðŸ‘‰-> finally\n",
      "finalizedðŸ‘‰-> finalize\n"
     ]
    }
   ],
   "source": [
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]\n",
    "\n",
    "for word in words:\n",
    "    print(word+\"ðŸ‘‰-> \"+lemmatizer.lemmatize(word,pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e61febe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eating', 'eats', 'eaten', 'writing', 'writes', 'programming', 'program', 'history', 'finally', 'finalized'] "
     ]
    }
   ],
   "source": [
    "lemma = [lemmatizer.lemmatize(word) for word in words]\n",
    "print(lemma,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5782f483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairly', 'sportingly')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"fairly\",pos='v'),lemmatizer.lemmatize(\"sportingly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f16cc",
   "metadata": {},
   "source": [
    "### `Lemmatization` v/s `Stemming`\n",
    "* Stemming: \"running\" -> \"run\", \"better\" -> \"better\", \"geese\" -> \"gees\"\n",
    "* Lemmatization: \"running\" -> \"run\", \"better\" -> \"good\", \"geese\" -> \"goose\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35de151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62ba64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba84933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8704fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1f28ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
